{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bibicaka2/colab/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJDTJjJi_0dk"
      },
      "source": [
        "\n",
        "import numpy as np # Xử lý một số toán học\n",
        "import matplotlib.pyplot as plt # Thư viện đồ thị trực quan, hình ảnh,...\n",
        "from pathlib import Path\n",
        "import os\n",
        "import cv2 \n",
        "import random\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_e7LZMgs5tA"
      },
      "source": [
        "# Mục mới"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S0nZH-2oUwz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY8E0uqaAGSi",
        "outputId": "61393631-1487-40f4-9d8b-937c061c5940"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgH7VKlYAUqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b665773b-6059-4adf-ba53-b7c7b6c4a65d"
      },
      "source": [
        "!cd \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!unzip -u \"/content/drive/MyDrive/Normal-20210323T012456Z-002.zip\" -d \"dataset\"\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Normal-20210323T012456Z-002.zip\n",
            "  inflating: dataset/Normal/N (47).tif  \n",
            "  inflating: dataset/Normal/N (49).tif  \n",
            "  inflating: dataset/Normal/N (63).tif  \n",
            "  inflating: dataset/Normal/N (91).tif  \n",
            "  inflating: dataset/Normal/N (248).tif  \n",
            "  inflating: dataset/Normal/N (35).tif  \n",
            "  inflating: dataset/Normal/N (20).tif  \n",
            "  inflating: dataset/Normal/N (34).tif  \n",
            "  inflating: dataset/Normal/N (48).tif  \n",
            "  inflating: dataset/Normal/N (56).tif  \n",
            "  inflating: dataset/Normal/N (97).tif  \n",
            "  inflating: dataset/Normal/N (30).tif  \n",
            "  inflating: dataset/Normal/N (57).tif  \n",
            "  inflating: dataset/Normal/N (90).tif  \n",
            "  inflating: dataset/Normal/N (99).tif  \n",
            "  inflating: dataset/Normal/N (58).tif  \n",
            "  inflating: dataset/Normal/N (105).tif  \n",
            "  inflating: dataset/Normal/N (102).tif  \n",
            "  inflating: dataset/Normal/N (98).tif  \n",
            "  inflating: dataset/Normal/N (62).tif  \n",
            "  inflating: dataset/Normal/N (106).tif  \n",
            "  inflating: dataset/Normal/N (68).tif  \n",
            "  inflating: dataset/Normal/N (54).tif  \n",
            "  inflating: dataset/Normal/N (103).tif  \n",
            "  inflating: dataset/Normal/N (96).tif  \n",
            "  inflating: dataset/Normal/N (92).tif  \n",
            "  inflating: dataset/Normal/N (107).tif  \n",
            "  inflating: dataset/Normal/N (59).tif  \n",
            "  inflating: dataset/Normal/N (93).tif  \n",
            "  inflating: dataset/Normal/N (64).tif  \n",
            "  inflating: dataset/Normal/N (66).tif  \n",
            "  inflating: dataset/Normal/N (65).tif  \n",
            "  inflating: dataset/Normal/N (109).tif  \n",
            "  inflating: dataset/Normal/N (69).tif  \n",
            "  inflating: dataset/Normal/N (95).tif  \n",
            "  inflating: dataset/Normal/N (80).tif  \n",
            "  inflating: dataset/Normal/N (52).tif  \n",
            "  inflating: dataset/Normal/N (81).tif  \n",
            "  inflating: dataset/Normal/N (76).tif  \n",
            "  inflating: dataset/Normal/N (245).tif  \n",
            "  inflating: dataset/Normal/N (70).tif  \n",
            "  inflating: dataset/Normal/N (33).tif  \n",
            "  inflating: dataset/Normal/N (94).tif  \n",
            "  inflating: dataset/Normal/N (111).tif  \n",
            "  inflating: dataset/Normal/N (71).tif  \n",
            "  inflating: dataset/Normal/N (79).tif  \n",
            "  inflating: dataset/Normal/N (84).tif  \n",
            "  inflating: dataset/Normal/N (167).tif  \n",
            "  inflating: dataset/Normal/N (67).tif  \n",
            "  inflating: dataset/Normal/N (77).tif  \n",
            "  inflating: dataset/Normal/N (101).tif  \n",
            "  inflating: dataset/Normal/N (85).tif  \n",
            "  inflating: dataset/Normal/N (74).tif  \n",
            "  inflating: dataset/Normal/N (73).tif  \n",
            "  inflating: dataset/Normal/N (61).tif  \n",
            "  inflating: dataset/Normal/N (87).tif  \n",
            "  inflating: dataset/Normal/N (112).tif  \n",
            "  inflating: dataset/Normal/N (78).tif  \n",
            "  inflating: dataset/Normal/N (60).tif  \n",
            "  inflating: dataset/Normal/N (100).tif  \n",
            "  inflating: dataset/Normal/N (83).tif  \n",
            "  inflating: dataset/Normal/N (72).tif  \n",
            "  inflating: dataset/Normal/N (50).tif  \n",
            "  inflating: dataset/Normal/N (86).tif  \n",
            "  inflating: dataset/Normal/N (22).tif  \n",
            "  inflating: dataset/Normal/N (25).tif  \n",
            "  inflating: dataset/Normal/N (23).tif  \n",
            "  inflating: dataset/Normal/N (104).tif  \n",
            "  inflating: dataset/Normal/N (16).tif  \n",
            "  inflating: dataset/Normal/N (17).tif  \n",
            "  inflating: dataset/Normal/N (19).tif  \n",
            "  inflating: dataset/Normal/N (89).tif  \n",
            "  inflating: dataset/Normal/N (75).tif  \n",
            "  inflating: dataset/Normal/N (13).tif  \n",
            "  inflating: dataset/Normal/N (18).tif  \n",
            "  inflating: dataset/Normal/N (24).tif  \n",
            "  inflating: dataset/Normal/N (51).tif  \n",
            "  inflating: dataset/Normal/N (55).tif  \n",
            "  inflating: dataset/Normal/N (27).tif  \n",
            "  inflating: dataset/Normal/N (41).tif  \n",
            "  inflating: dataset/Normal/N (29).tif  \n",
            "  inflating: dataset/Normal/N (15).tif  \n",
            "  inflating: dataset/Normal/N (28).tif  \n",
            "  inflating: dataset/Normal/N (26).tif  \n",
            "  inflating: dataset/Normal/N (40).tif  \n",
            "  inflating: dataset/Normal/N (53).tif  \n",
            "  inflating: dataset/Normal/N (14).tif  \n",
            "  inflating: dataset/Normal/N (82).tif  \n",
            "  inflating: dataset/Normal/N (375).tif  \n",
            "  inflating: dataset/Normal/N (150).tif  \n",
            "  inflating: dataset/Normal/N (108).tif  \n",
            "  inflating: dataset/Normal/N (110).tif  \n",
            "  inflating: dataset/Normal/N (88).tif  \n",
            "  inflating: dataset/Normal/N (113).tif  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U8x1ZHhBkJM"
      },
      "source": [
        "  import numpy as np # Xử lý một số toán học\n",
        "  import matplotlib.pyplot as plt # Thư viện đồ thị trực quan, hình ảnh,...\n",
        "  from pathlib import Path\n",
        "  import os\n",
        "  import cv2 \n",
        "  import random\n",
        "  import pickle\n",
        "  import tensorflow as tf\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "  from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6yy5WQpBkTM"
      },
      "source": [
        "data_dir = \"/content/dataset\"\n",
        "data_dir = Path(data_dir)  \n",
        "categories = os.listdir(data_dir)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI29cLHWBkay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ee2718-88c1-472a-fc68-76cec5c59aa0"
      },
      "source": [
        "count_image = len(list(data_dir.glob(\"*/*.tif\")))\n",
        "print(count_image)\n",
        "print(len(categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Diti9No1AUyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "4e5af3e0-0e27-4f79-fc03-20de667993bf"
      },
      "source": [
        "categories.index('Daffodil')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-f4201b115d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Daffodil'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: 'Daffodil' is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex6HVTdBBz9V"
      },
      "source": [
        "training_data = []  # Toàn bộ dữ liệu chúng ta có thể sử dụng, phân biệt giữa training data, x_train, y_train, x_test, y_test, x_val và y_val\n",
        "# training data = [x_train, y_train] + [x_test, y_test] + [x_val, y_val]\n",
        "\n",
        "IMG_SIZE = 200  # Trong hướng dẫn này, lựa chọn đưa toàn bộ ảnh về cùng kích thước 200 x 200, (bộ dữ liệu với nhiều loại kích thước ảnh)\n",
        "def create_training_data():\n",
        "  for category in categories: # Duyệt qua từng folder label\n",
        "    path = os.path.join(data_dir, category) # tạo một path tạm đến folder label đó \n",
        "    label_number = categories.index(category) # label thứ mấy trong mảng categories chứa các label\n",
        "    for img in os.listdir(path):  # duyệt qua toàn bộ ảnh trong path\n",
        "      try:\n",
        "        img_array_gray = cv2.imread(os.path.join(path, img), cv2.IMREAD_ANYCOLOR) # Đọc mảng giá trị của ảnh, ở đây không chuyển ảnh thành gray\n",
        "        new_img_array = cv2.resize(img_array_gray, (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_AREA)  # Chuyển ảnh về cùng kích thước\n",
        "        training_data.append([new_img_array, label_number]) # Lưu ảnh cùng label tương ứng vào training_data\n",
        "      except Exception as e:\n",
        "        pass\n",
        "\n",
        "create_training_data()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rblm10ODB4LJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ece8db-83f1-4b8d-ba9a-fb009fa70e61"
      },
      "source": [
        "print(len(training_data))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZb4kdwB6HE"
      },
      "source": [
        "random.shuffle(training_data) # xáo trộn dữ liệu"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdGuCnn7B9uY"
      },
      "source": [
        "\n",
        "# Tạo 2 mảng để lưu samples và labels theo cùng index tương ứng\n",
        "X = []  # samples\n",
        "y = []  # labels"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiTGRLByCATo"
      },
      "source": [
        "for feature, label in training_data:  # Mỗi phần tử trong training_data có dạng [feature, label] trong đó feature = new_img_array và label = label_number\n",
        "  X.append(feature)\n",
        "  y.append(label)\n",
        "\n",
        "# X bây giờ chứa toàn bộ features\n",
        "# Chuyển X về dạng ma trận\n",
        "# -1 ở đây tương đương với số lượng features, dùng -1 numpy tự hiểu là ứng với số lượng của feature hiện có trong X\n",
        "# Vì không chuyển thành ảnh trắng đen nên ảnh có 3 kênh màu, tham số cuối cùng trong reshape\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95TAy69oCBvE"
      },
      "source": [
        "# Bước này dùng để lưu X và y vào một file theo định dạng có cấu trúc để khỏi phải chạy lại hàm tạo X, y phía trên - khá tốn thời gian cho việc tạo lại từ đầu\n",
        "pickle_out = open(\"/content/dataset/X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"/content/dataset/y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CULBYBhcCDAI"
      },
      "source": [
        "# Đọc lại file cấu trúc đã lưu\n",
        "pickle_in = open(\"/content/dataset/X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "pickle_in.close()\n",
        "\n",
        "pickle_in = open(\"/content/dataset/y.pickle\", \"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "pickle_in.close()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeQBBXyzCEv4"
      },
      "source": [
        "X = X/255  # Tinh giảm giá trị trong điểm ảnh (vì giá trị màu chạy từ 0 --> 255 nên mới có con số 255 ở đây)\n",
        "y = to_categorical(y) # one hot\n",
        "# ví dụ y_number = 14 thì y = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtFafmYCGea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9bb4dd4-7b6a-48d5-de08-baaaf0111c5b"
      },
      "source": [
        "model = Sequential() #  Khởi tạo một một mô hình neural\n",
        "\n",
        "# Bắt đầu của mạng thêm một Convolutional layer với các tham số trên\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "# Lớp ban đầu này phải truyền cho mạng biết input_shape ban đầu là bao nhiêu chính là (weight x heigh x depth) của ảnh\n",
        "# padding chỉ có thể chọn 1 trong 2 giá trị `same` hoặc `valid`\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=X.shape[1:], padding=\"same\"))\n",
        "\n",
        "# Thêm cho layer trên một hàm kích hoạt\n",
        "model.add(Activation(\"relu\"))\n",
        "# Tinh giảm số neural của output nếu cần thiết\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "# Làm phẳng neuron, bắt đầu fully connected\n",
        "model.add(Flatten())\n",
        "# Tạo một layer\n",
        "model.add(Dense(128))\n",
        "# Thêm hàm kích hoạt\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation(\"relu\"))\n",
        "# output\n",
        "model.add(Dense(len(categories)))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "# Cung cấp cho mô hình hàm loss function lựa chọn, thuật toán tối ưu\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary() # xem chi tiết mô hình xây dựng của chính mình\n",
        "\n",
        "# Cuối cùng đào tạo nó\n",
        "model.fit(X, y, batch_size=200, epochs=14)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 200, 200, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 200, 200, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 98, 98, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 98, 98, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 47, 47, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 47, 47, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 67712)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               8667264   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 8,768,833\n",
            "Trainable params: 8,768,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/14\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.6932 - accuracy: 1.0000\n",
            "Epoch 2/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.1638e-05 - accuracy: 1.0000\n",
            "Epoch 3/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.3303e-09 - accuracy: 1.0000\n",
            "Epoch 4/14\n",
            "1/1 [==============================] - 5s 5s/step - loss: 5.6760e-14 - accuracy: 1.0000\n",
            "Epoch 5/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.0312e-18 - accuracy: 1.0000\n",
            "Epoch 6/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 7.0352e-23 - accuracy: 1.0000\n",
            "Epoch 7/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.9767e-27 - accuracy: 1.0000\n",
            "Epoch 8/14\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.5952e-31 - accuracy: 1.0000\n",
            "Epoch 9/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.1243e-35 - accuracy: 1.0000\n",
            "Epoch 10/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/14\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/14\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f618bb7a350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Lg_NisCIIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a717903e-afa2-4640-b8c4-728cd2a9abfb"
      },
      "source": [
        "# Cuối cùng là dùng một mẫu để dự đoán\n",
        "y_hat = model.predict(X[2:4])\n",
        "y_label = np.argmax(y_hat, axis=1)\n",
        "print(y_label)\n",
        "print(y[2])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0]\n",
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}